# 最大规模

- 节点数不超过 5000
- Pod 总数不超过 150000
- 容器总数不超过 300000
- 每个节点的 pod 数量不超过 100

# 资源需求

管理节点

| 节点规模       | 资源需求 | 备注 |
| -------------- | -------- | ---- |
| 1-5 个节点     | 1C4G     |      |
| 6-10 个节点    | 2C8G     |      |
| 11-100 个节点  | 4C16G    |      |
| 101-250 个节点 | 8C32G    |      |
| 251-500 个节点 | 16C64G   |      |
| 超过 500 节点  | 32C120G  |      |

# 稳定性自查项

## 组件挂掉/拥塞

任意组件挂掉/拥塞, 会影响已经运行的容器么?

> 举例, 如果APIServer异常,拥塞, 此时可能若干节点的 kubelet 均无法正常上报心跳，在 controller 处会将其置为 not ready。而后可能会导致由 rs 触发重启的重建，service 摘除相对应节点上容器的流量等等。而实际上，这些节点的容器其实原本是正常运行的。出现问题的，仅仅是 apiserver 的拥塞而已。又比如，采用的网络方案，如果网络元数据的存储故障了，是否会导致现有容器的网络受到影响，是否会导致网络瘫痪。

## 异常告警

任意组件异常, 都会有告警和对应的处理方式吗?

> 这里以 etcd 为例。毫无疑问，etcd 是 Kubernetes 的核心中枢。但是 etcd 并不是想象中那么万无一失。在实际生产实践中，遇到过多次莫名其妙的故障，导致整个 etcd 集群无法写入数据，甚至完全故障。最后不得不启动先前的故障预案。在之前的故障预案中，我们做了多种计划和多次演练，包括上策：从 etcd 集群原节点恢复，中策：将数据迁移到新的节点进行恢复，以及下策：从定时备份的数据中恢复。如果从定时备份的数据中恢复，则难免会有一部分数据丢失。在实际中，我们遇到过的最坏情况是将数据迁移到新节点进行集群重建恢复。但是三种情况的演练仍然是必要的，以确保在最坏情况下，仍然能最大限度的保障集群的稳定和安全。

## 组件损坏

任意组件损坏, 集群都能恢复么?

组件的故障异常既然不可避免，那么如何对组件进行监控告警，如何定义告警的规则和和方式，以及告警后如何接入自动化的处理，就需要进行认真的思考。比如，各个组件所在的容器 / 物理机需要配合相应的资源监控告警，组件本身也需要进行健康检查等方式的监控告警，甚而，还需要对组件本身的性能数据进行监控告警。